{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:29:25.043302Z",
     "start_time": "2025-05-29T13:29:23.119813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi, list_models, model_info, hf_hub_download\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class HuggingfaceScraper:\n",
    "    def __init__(self, token:str, max_workers: int = 5, batch_size: int = 100):\n",
    "        self.api = HfApi(token=token)\n",
    "        self.max_workers = max_workers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def get_readme_from_model(self, model_id) -> str:\n",
    "        try:\n",
    "            readme_content = hf_hub_download(\n",
    "                repo_id=model_id,\n",
    "                filename=\"README.md\",\n",
    "                token=self.api.token,\n",
    "            )\n",
    "            \n",
    "            with open(readme_content, 'r', encoding='utf-8') as f:\n",
    "                readme_text = f.read()\n",
    "                \n",
    "            return readme_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching README for {model_id}: {e}\")\n",
    "            return ''\n",
    "        \n",
    "    def process_single_model(self, model_id: str) -> Optional[Dict]:\n",
    "        try:\n",
    "            info = model_info(model_id, token=self.api.token)\n",
    "            card_data = info.cardData if hasattr(info, 'cardData') and info.cardData else {}\n",
    "\n",
    "            readme = self.get_readme_from_model(model_id)\n",
    "            \n",
    "            return {\n",
    "                'model_id': model_id,\n",
    "                'base_model': getattr(card_data, 'base_model', None),\n",
    "                'author': getattr(info, 'author', None),\n",
    "                'readme_file': readme,\n",
    "                'license' : getattr(card_data, 'license', None),\n",
    "                'language' : getattr(card_data, 'language', None),\n",
    "                'downloads': getattr(info, 'downloads', 0),\n",
    "                'likes': getattr(info, 'likes', 0),\n",
    "                'tags': ', '.join(info.tags) if hasattr(info, 'tags') and info.tags else '',\n",
    "                'pipeline_tag': getattr(info, 'pipeline_tag', None),\n",
    "                'library_name': getattr(info, 'library_name', None),\n",
    "                'created_at': getattr(info, 'created_at', None),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model_id}: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def process_batch_threaded(self, model_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Process a batch of models using ThreadPoolExecutor\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_model = {\n",
    "                executor.submit(self.process_single_model, model_id): model_id \n",
    "                for model_id in model_ids\n",
    "            }\n",
    "            \n",
    "            # Collect results with progress bar\n",
    "            for future in tqdm(as_completed(future_to_model), \n",
    "                             total=len(model_ids), \n",
    "                             desc=f\"Processing batch\"):\n",
    "                try:\n",
    "                    result = future.result(timeout=60)  # 60 second timeout\n",
    "                    if result:\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    model_id = future_to_model[future]\n",
    "                    logger.error(f\"Timeout/Error for {model_id}: {e}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def scrape_models_checkpoint(self, checkpoint_file:str =\"scraping_checkpoint.json\") -> pd.DataFrame:\n",
    "        \n",
    "        checkpoint_data = []\n",
    "        start_index = 0\n",
    "        \n",
    "        if Path(checkpoint_file).exists():\n",
    "            try:\n",
    "                with open(checkpoint_file, 'r') as f:\n",
    "                    checkpoint_data = json.load(f)\n",
    "                start_index = len(checkpoint_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load checkpoint file: {e}\")\n",
    "                \n",
    "        print(\"Fetching models from Hugging Face Hub...\")\n",
    "        models = list(list_models(limit=1100))\n",
    "        print(\"Models fetched.\")\n",
    "        \n",
    "        # Process remaining models\n",
    "        models_to_process = models[start_index:]\n",
    "        all_data = checkpoint_data.copy()\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(models_to_process), self.batch_size):\n",
    "            batch_models = models_to_process[i:i + self.batch_size]\n",
    "            batch_ids = [m.modelId for m in batch_models]\n",
    "            \n",
    "            print(f\"Processing batch {i//self.batch_size + 1}/{(len(models_to_process)-1)//self.batch_size + 1}\")\n",
    "            \n",
    "                        # Process batch\n",
    "            batch_results = self.process_batch_threaded(batch_ids)\n",
    "            all_data.extend(batch_results)\n",
    "            \n",
    "            # Save checkpoint\n",
    "            \n",
    "            try:\n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    json.dump(all_data, f, indent=2, default=str)\n",
    "                logger.info(f\"Checkpoint saved: {len(all_data)} models processed\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Could not save checkpoint: {e}\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1)  # Brief pause between batches\n",
    "        \n",
    "        return pd.DataFrame(all_data)\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    scraper = HuggingfaceScraper(token=\"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\", max_workers=5, batch_size=100)\n",
    "    \n",
    "    df = scraper.scrape_models_checkpoint(checkpoint_file=\"scraping_checkpoint.json\")\n",
    "            \n",
    "    "
   ],
   "id": "804a9e17139eea21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/NLP/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching models from Hugging Face Hub...\n",
      "Models fetched.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T10:41:57.760438Z",
     "start_time": "2025-05-29T10:41:57.736375Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(200)",
   "id": "3c0953e216dfcc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      model_id  \\\n",
       "0                  ByteDance-Seed/BAGEL-7B-MoT   \n",
       "1                mistralai/Devstral-Small-2505   \n",
       "2                 deepseek-ai/DeepSeek-R1-0528   \n",
       "3                            sarvamai/sarvam-m   \n",
       "4        google/gemma-3n-E4B-it-litert-preview   \n",
       "..                                         ...   \n",
       "195                            fofr/sdxl-emoji   \n",
       "196     prithivMLmods/Qwen2-VL-OCR-2B-Instruct   \n",
       "197  deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B   \n",
       "198                 Qwen/Qwen2.5-1.5B-Instruct   \n",
       "199     aleksa-codes/flux-ghibsky-illustration   \n",
       "\n",
       "                                      base_model          author  \\\n",
       "0                     [Qwen/Qwen2.5-7B-Instruct]  ByteDance-Seed   \n",
       "1               [mistralai/Devstrall-Small-2505]       mistralai   \n",
       "2                                           None     deepseek-ai   \n",
       "3    [mistralai/Mistral-Small-3.1-24B-Base-2503]        sarvamai   \n",
       "4                                           None          google   \n",
       "..                                           ...             ...   \n",
       "195     stabilityai/stable-diffusion-xl-base-1.0            fofr   \n",
       "196                  [Qwen/Qwen2-VL-2B-Instruct]   prithivMLmods   \n",
       "197                                         None     deepseek-ai   \n",
       "198                            Qwen/Qwen2.5-1.5B            Qwen   \n",
       "199                 black-forest-labs/FLUX.1-dev    aleksa-codes   \n",
       "\n",
       "                                           readme_file                license  \\\n",
       "0    ---\\nlicense: apache-2.0\\nbase_model:\\n- Qwen/...             apache-2.0   \n",
       "1    ---\\nlanguage:\\n- en\\n- fr\\n- de\\n- es\\n- pt\\n...             apache-2.0   \n",
       "2                                                                        None   \n",
       "3    ---\\nlibrary_name: transformers\\nlicense: apac...             apache-2.0   \n",
       "4    ---\\nlicense: gemma\\npipeline_tag: image-text-...                  gemma   \n",
       "..                                                 ...                    ...   \n",
       "195  ---\\nlicense: creativeml-openrail-m\\ntags:\\n  ...  creativeml-openrail-m   \n",
       "196  ---\\nlicense: apache-2.0\\ndatasets:\\n- unsloth...             apache-2.0   \n",
       "197  ---\\nlicense: mit\\nlibrary_name: transformers\\...                    mit   \n",
       "198  ---\\nlicense: apache-2.0\\nlicense_link: https:...             apache-2.0   \n",
       "199  ---\\ntags:\\n- text-to-image\\n- diffusers\\n- lo...                  other   \n",
       "\n",
       "                                              language  downloads  likes  \\\n",
       "0                                                 None       5831    826   \n",
       "1    [en, fr, de, es, pt, it, ja, ko, ru, zh, ar, f...     121541    635   \n",
       "2                                                 None          0    968   \n",
       "3         [en, bn, hi, kn, gu, mr, ml, or, pa, ta, te]       2378    192   \n",
       "4                                                 None          0    628   \n",
       "..                                                 ...        ...    ...   \n",
       "195                                               None        479    472   \n",
       "196                                               [en]     126345     77   \n",
       "197                                               None    1358368   1201   \n",
       "198                                               [en]    1310905    440   \n",
       "199                                               None       2391    275   \n",
       "\n",
       "                                                  tags          pipeline_tag  \\\n",
       "0    bagel-mot, any-to-any, arxiv:2505.14683, base_...            any-to-any   \n",
       "1    vllm, safetensors, mistral, text2text-generati...  text2text-generation   \n",
       "2    safetensors, deepseek_v3, conversational, cust...       text-generation   \n",
       "3    transformers, safetensors, mistral, text-gener...       text-generation   \n",
       "4    image-text-to-text, arxiv:1905.07830, arxiv:19...    image-text-to-text   \n",
       "..                                                 ...                   ...   \n",
       "195  diffusers, text-to-image, stable-diffusion, lo...         text-to-image   \n",
       "196  transformers, safetensors, qwen2_vl, image-tex...    image-text-to-text   \n",
       "197  transformers, safetensors, qwen2, text-generat...       text-generation   \n",
       "198  transformers, safetensors, qwen2, text-generat...       text-generation   \n",
       "199  diffusers, text-to-image, lora, template:sd-lo...         text-to-image   \n",
       "\n",
       "     library_name                 created_at  \n",
       "0       bagel-mot  2025-05-19 23:27:50+00:00  \n",
       "1            vllm  2025-05-12 21:49:21+00:00  \n",
       "2            None  2025-05-28 09:46:42+00:00  \n",
       "3    transformers  2025-05-20 06:39:05+00:00  \n",
       "4            None  2025-05-18 19:24:14+00:00  \n",
       "..            ...                        ...  \n",
       "195     diffusers  2024-06-20 09:05:06+00:00  \n",
       "196  transformers  2024-12-19 01:57:34+00:00  \n",
       "197  transformers  2025-01-20 09:04:18+00:00  \n",
       "198  transformers  2024-09-17 14:10:29+00:00  \n",
       "199     diffusers  2024-08-20 13:59:25+00:00  \n",
       "\n",
       "[200 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>base_model</th>\n",
       "      <th>author</th>\n",
       "      <th>readme_file</th>\n",
       "      <th>license</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>library_name</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteDance-Seed/BAGEL-7B-MoT</td>\n",
       "      <td>[Qwen/Qwen2.5-7B-Instruct]</td>\n",
       "      <td>ByteDance-Seed</td>\n",
       "      <td>---\\nlicense: apache-2.0\\nbase_model:\\n- Qwen/...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5831</td>\n",
       "      <td>826</td>\n",
       "      <td>bagel-mot, any-to-any, arxiv:2505.14683, base_...</td>\n",
       "      <td>any-to-any</td>\n",
       "      <td>bagel-mot</td>\n",
       "      <td>2025-05-19 23:27:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistralai/Devstral-Small-2505</td>\n",
       "      <td>[mistralai/Devstrall-Small-2505]</td>\n",
       "      <td>mistralai</td>\n",
       "      <td>---\\nlanguage:\\n- en\\n- fr\\n- de\\n- es\\n- pt\\n...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>[en, fr, de, es, pt, it, ja, ko, ru, zh, ar, f...</td>\n",
       "      <td>121541</td>\n",
       "      <td>635</td>\n",
       "      <td>vllm, safetensors, mistral, text2text-generati...</td>\n",
       "      <td>text2text-generation</td>\n",
       "      <td>vllm</td>\n",
       "      <td>2025-05-12 21:49:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-0528</td>\n",
       "      <td>None</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>safetensors, deepseek_v3, conversational, cust...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-28 09:46:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sarvamai/sarvam-m</td>\n",
       "      <td>[mistralai/Mistral-Small-3.1-24B-Base-2503]</td>\n",
       "      <td>sarvamai</td>\n",
       "      <td>---\\nlibrary_name: transformers\\nlicense: apac...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>[en, bn, hi, kn, gu, mr, ml, or, pa, ta, te]</td>\n",
       "      <td>2378</td>\n",
       "      <td>192</td>\n",
       "      <td>transformers, safetensors, mistral, text-gener...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-05-20 06:39:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemma-3n-E4B-it-litert-preview</td>\n",
       "      <td>None</td>\n",
       "      <td>google</td>\n",
       "      <td>---\\nlicense: gemma\\npipeline_tag: image-text-...</td>\n",
       "      <td>gemma</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>image-text-to-text, arxiv:1905.07830, arxiv:19...</td>\n",
       "      <td>image-text-to-text</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-18 19:24:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>fofr/sdxl-emoji</td>\n",
       "      <td>stabilityai/stable-diffusion-xl-base-1.0</td>\n",
       "      <td>fofr</td>\n",
       "      <td>---\\nlicense: creativeml-openrail-m\\ntags:\\n  ...</td>\n",
       "      <td>creativeml-openrail-m</td>\n",
       "      <td>None</td>\n",
       "      <td>479</td>\n",
       "      <td>472</td>\n",
       "      <td>diffusers, text-to-image, stable-diffusion, lo...</td>\n",
       "      <td>text-to-image</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>2024-06-20 09:05:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>prithivMLmods/Qwen2-VL-OCR-2B-Instruct</td>\n",
       "      <td>[Qwen/Qwen2-VL-2B-Instruct]</td>\n",
       "      <td>prithivMLmods</td>\n",
       "      <td>---\\nlicense: apache-2.0\\ndatasets:\\n- unsloth...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>[en]</td>\n",
       "      <td>126345</td>\n",
       "      <td>77</td>\n",
       "      <td>transformers, safetensors, qwen2_vl, image-tex...</td>\n",
       "      <td>image-text-to-text</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2024-12-19 01:57:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B</td>\n",
       "      <td>None</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td>---\\nlicense: mit\\nlibrary_name: transformers\\...</td>\n",
       "      <td>mit</td>\n",
       "      <td>None</td>\n",
       "      <td>1358368</td>\n",
       "      <td>1201</td>\n",
       "      <td>transformers, safetensors, qwen2, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-01-20 09:04:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Qwen/Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>Qwen/Qwen2.5-1.5B</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>---\\nlicense: apache-2.0\\nlicense_link: https:...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>[en]</td>\n",
       "      <td>1310905</td>\n",
       "      <td>440</td>\n",
       "      <td>transformers, safetensors, qwen2, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2024-09-17 14:10:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>aleksa-codes/flux-ghibsky-illustration</td>\n",
       "      <td>black-forest-labs/FLUX.1-dev</td>\n",
       "      <td>aleksa-codes</td>\n",
       "      <td>---\\ntags:\\n- text-to-image\\n- diffusers\\n- lo...</td>\n",
       "      <td>other</td>\n",
       "      <td>None</td>\n",
       "      <td>2391</td>\n",
       "      <td>275</td>\n",
       "      <td>diffusers, text-to-image, lora, template:sd-lo...</td>\n",
       "      <td>text-to-image</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>2024-08-20 13:59:25+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d3f0a2d89e01320"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
