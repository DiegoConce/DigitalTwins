{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:51:27.134723Z",
     "start_time": "2025-06-12T10:51:27.130763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "1d41ad80044b9777",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG: Query based retrival using embeddings\n",
    "### Overview\n",
    "The goal of this step is to filter and rank articles based on their embedding similarity scores to a user-provided prompt. This is done using a pre-trained model to convert the prompt into embeddings, and then comparing these embeddings with the embeddings of articles stored in a DataFrame. <br>\n",
    "\n",
    "The open source model is the same used before in the preprocessing step, which is [`jinaai/jina-embeddings-v3`](https://huggingface.co/jinaai/jina-embeddings-v3).\n",
    "\n",
    "#### Possibile future improvements\n",
    "The current filtering approach based on user queries can be expanded by incorporating additional criteria such as number of downloads, likes, or publication date. This a simple implementation which does not require any computational resources.<br>\n",
    "Moreover, the retrieval performance can be improved by experimenting with alternative similarity metrics such as cosine similarity or Euclidean distance or trying with another model.\n"
   ],
   "id": "73a3cee99e081526"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T10:51:28.399807Z",
     "start_time": "2025-06-12T10:51:28.394392Z"
    }
   },
   "source": [
    "embedding_model = \"jinaai/jina-embeddings-v3\"\n",
    "\n",
    "\n",
    "def convert_prompt_to_embedding(prompt):\n",
    "    \"\"\"\n",
    "    Converts text prompt to embeddings using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Input text to convert to embeddings\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Embedding vector representation of the input text\n",
    "    \"\"\"\n",
    "    model = AutoModel.from_pretrained(embedding_model, trust_remote_code=True).to(\"cpu\")  # for now cpu\n",
    "    embedding = model.encode(prompt, task=\"text-matching\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def compute_score(embeddings, prompt):\n",
    "    models_embedding = np.array(embeddings)\n",
    "    return np.dot(models_embedding, prompt)\n",
    "\n",
    "\n",
    "def filter_by_score(data, prompt, range=10):\n",
    "    \"\"\"\n",
    "    Filters and ranks models based on embedding similarity scores.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing 'embeddings' column\n",
    "        prompt (numpy.ndarray): Prompt embedding to compare against\n",
    "        range (int, optional): Number of top models to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Top N articles sorted by similarity score\n",
    "    \"\"\"\n",
    "\n",
    "    data['embeddings'] = data['embeddings'].apply(\n",
    "        lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else x)  #da sistemare\n",
    "\n",
    "    data['score'] = data['embeddings'].progress_apply(lambda x: compute_score(x, prompt))\n",
    "    data.sort_values(by='score', ascending=False, inplace=True)\n",
    "    return data.head(range)\n",
    "\n",
    "\n",
    "def filter_by_user_prompt(data, user_prompt):\n",
    "    prompt_embedding = convert_prompt_to_embedding(user_prompt)\n",
    "    data = filter_by_score(data, prompt_embedding)\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:51:21.683827Z",
     "start_time": "2025-06-12T10:51:18.954532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"huggingface_models_embeddings.csv\")\n",
    "df.head()"
   ],
   "id": "84ee952c5304c6c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                model_id base_model       author  \\\n",
       "0           deepseek-ai/DeepSeek-R1-0528        NaN  deepseek-ai   \n",
       "1  deepseek-ai/DeepSeek-R1-0528-Qwen3-8B        NaN  deepseek-ai   \n",
       "2  google/gemma-3n-E4B-it-litert-preview        NaN       google   \n",
       "3      osmosis-ai/Osmosis-Structure-0.6B        NaN   osmosis-ai   \n",
       "4                  ResembleAI/chatterbox        NaN   ResembleAI   \n",
       "\n",
       "                                         readme_file     license language  \\\n",
       "0  DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...         mit      NaN   \n",
       "1  DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...         mit      NaN   \n",
       "2  [!Note]\\nThis repository corresponds to the Pr...       gemma      NaN   \n",
       "3  Osmosis-Structure-0.6B: Small Language Model f...  apache-2.0      NaN   \n",
       "4  Chatterbox TTS\\nMade with  ‚ù§Ô∏è  by\\nWe're excit...         mit   ['en']   \n",
       "\n",
       "   downloads  likes                                               tags  \\\n",
       "0      47886   1702  transformers, safetensors, deepseek_v3, text-g...   \n",
       "1      72595    629  transformers, safetensors, qwen3, text-generat...   \n",
       "2          0    882  image-text-to-text, arxiv:1905.07830, arxiv:19...   \n",
       "3        554    229  safetensors, gguf, license:apache-2.0, endpoin...   \n",
       "4          0    560  chatterbox, text-to-speech, speech generation,...   \n",
       "\n",
       "         pipeline_tag  library_name                 created_at  \\\n",
       "0     text-generation  transformers  2025-05-28 09:46:42+00:00   \n",
       "1     text-generation  transformers  2025-05-29 11:07:47+00:00   \n",
       "2  image-text-to-text           NaN  2025-05-18 19:24:14+00:00   \n",
       "3                 NaN           NaN  2025-05-28 15:39:48+00:00   \n",
       "4      text-to-speech    chatterbox  2025-04-24 12:03:33+00:00   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.1295202076435089, -0.03313147649168968, 0.0...  \n",
       "1  [0.11936206370592117, -0.02954871952533722, 0....  \n",
       "2  [0.12827537953853607, -0.11014561355113983, 0....  \n",
       "3  [0.1758263260126114, 0.06860576570034027, 0.04...  \n",
       "4  [0.24660152196884155, 0.07107454538345337, 0.0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>base_model</th>\n",
       "      <th>author</th>\n",
       "      <th>readme_file</th>\n",
       "      <th>license</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>library_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-0528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td>DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47886</td>\n",
       "      <td>1702</td>\n",
       "      <td>transformers, safetensors, deepseek_v3, text-g...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-05-28 09:46:42+00:00</td>\n",
       "      <td>[0.1295202076435089, -0.03313147649168968, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-0528-Qwen3-8B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td>DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72595</td>\n",
       "      <td>629</td>\n",
       "      <td>transformers, safetensors, qwen3, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-05-29 11:07:47+00:00</td>\n",
       "      <td>[0.11936206370592117, -0.02954871952533722, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemma-3n-E4B-it-litert-preview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "      <td>[!Note]\\nThis repository corresponds to the Pr...</td>\n",
       "      <td>gemma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>image-text-to-text, arxiv:1905.07830, arxiv:19...</td>\n",
       "      <td>image-text-to-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-18 19:24:14+00:00</td>\n",
       "      <td>[0.12827537953853607, -0.11014561355113983, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osmosis-ai/Osmosis-Structure-0.6B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>osmosis-ai</td>\n",
       "      <td>Osmosis-Structure-0.6B: Small Language Model f...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>554</td>\n",
       "      <td>229</td>\n",
       "      <td>safetensors, gguf, license:apache-2.0, endpoin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-28 15:39:48+00:00</td>\n",
       "      <td>[0.1758263260126114, 0.06860576570034027, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResembleAI/chatterbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResembleAI</td>\n",
       "      <td>Chatterbox TTS\\nMade with  ‚ù§Ô∏è  by\\nWe're excit...</td>\n",
       "      <td>mit</td>\n",
       "      <td>['en']</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>chatterbox, text-to-speech, speech generation,...</td>\n",
       "      <td>text-to-speech</td>\n",
       "      <td>chatterbox</td>\n",
       "      <td>2025-04-24 12:03:33+00:00</td>\n",
       "      <td>[0.24660152196884155, 0.07107454538345337, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example with models from Hugging Face",
   "id": "ad4ae9835a844b0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:22:17.081528Z",
     "start_time": "2025-06-12T10:21:26.715346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model prompts\n",
    "user_prompts = [\n",
    "    \"What is the best model for text generation?\",\n",
    "    \"Which model should I use for sentiment analysis?\",\n",
    "    \"Find top models for image classification.\",\n",
    "    \"Best models for summarization tasks?\",\n",
    "    \"What are the newest models for code generation?\",\n",
    "    \"Top-performing models for question answering?\",\n",
    "    \"Which models support Italian language?\",\n",
    "    \"Best lightweight models for mobile deployment.\",\n",
    "    \"Which models are most popular on Hugging Face?\",\n",
    "    \"Find models optimized for speed and low latency.\"\n",
    "]\n",
    "\n",
    "# Log results\n",
    "with open(\"models_results_log.txt\", \"w\", encoding=\"utf-8\") as log_file:\n",
    "    for i, prompt in enumerate(user_prompts, 1):\n",
    "        log_file.write(f\"\\n--- Query {i}: {prompt} ---\\n\")\n",
    "        filtered_df = filter_by_user_prompt(df, prompt)\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            log_file.write(f\"\\n{row['model_id']} | score: {row['score']:.4f}\\n\")\n",
    "            log_file.write(f\"Author: {row['author']}\\n\")\n",
    "            log_file.write(f\"Pipeline Tag: {row['pipeline_tag']}\\n\")\n",
    "            log_file.write(f\"ReadmeFile, first 500 characters: {row['readme_file'][:500]}\\n\")\n",
    "            log_file.write(\"-\" * 50 + \"\\n\")\n",
    "        log_file.write(\"\\n\")"
   ],
   "id": "bb2f36e33feadf8a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, prompt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(user_prompts, \u001B[32m1\u001B[39m):\n\u001B[32m     18\u001B[39m     log_file.write(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m--- Query \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprompt\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m ---\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     filtered_df = filter_by_user_prompt(df, prompt)\n\u001B[32m     20\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m _, row \u001B[38;5;129;01min\u001B[39;00m filtered_df.iterrows():\n\u001B[32m     21\u001B[39m         log_file.write(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[33m'\u001B[39m\u001B[33mmodel_id\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[33m'\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 49\u001B[39m, in \u001B[36mfilter_by_user_prompt\u001B[39m\u001B[34m(data, user_prompt)\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfilter_by_user_prompt\u001B[39m(data, user_prompt):\n\u001B[32m     48\u001B[39m     prompt_embedding = convert_prompt_to_embedding(user_prompt)\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m     data = filter_by_score(data, prompt_embedding)\n\u001B[32m     50\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mfilter_by_score\u001B[39m\u001B[34m(data, prompt, range)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfilter_by_score\u001B[39m(data, prompt, \u001B[38;5;28mrange\u001B[39m=\u001B[32m10\u001B[39m):\n\u001B[32m     27\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[33;03m    Filters and ranks models based on embedding similarity scores.\u001B[39;00m\n\u001B[32m     29\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     36\u001B[39m \u001B[33;03m        pd.DataFrame: Top N articles sorted by similarity score\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m     data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m].apply(\n\u001B[32m     40\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m x: np.array(ast.literal_eval(x)) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x)  \u001B[38;5;66;03m#da sistemare\u001B[39;00m\n\u001B[32m     42\u001B[39m     data[\u001B[33m'\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m].progress_apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: compute_score(x, prompt))\n\u001B[32m     43\u001B[39m     data.sort_values(by=\u001B[33m'\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m'\u001B[39m, ascending=\u001B[38;5;28;01mFalse\u001B[39;00m, inplace=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4789\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4790\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4791\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4796\u001B[39m     **kwargs,\n\u001B[32m   4797\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4799\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4800\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4915\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4916\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4917\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m SeriesApply(\n\u001B[32m   4918\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4919\u001B[39m         func,\n\u001B[32m   4920\u001B[39m         convert_dtype=convert_dtype,\n\u001B[32m   4921\u001B[39m         by_row=by_row,\n\u001B[32m   4922\u001B[39m         args=args,\n\u001B[32m   4923\u001B[39m         kwargs=kwargs,\n\u001B[32m-> \u001B[39m\u001B[32m4924\u001B[39m     ).apply()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1424\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1426\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1427\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_standard()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1501\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1502\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1503\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1504\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1505\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1506\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1507\u001B[39m mapped = obj._map_values(\n\u001B[32m   1508\u001B[39m     mapper=curried, na_action=action, convert=\u001B[38;5;28mself\u001B[39m.convert_dtype\n\u001B[32m   1509\u001B[39m )\n\u001B[32m   1511\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1512\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1513\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1514\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    918\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    919\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer(values, mapper, convert=convert)\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mlib.pyx:2972\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[24]\u001B[39m\u001B[32m, line 40\u001B[39m, in \u001B[36mfilter_by_score.<locals>.<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfilter_by_score\u001B[39m(data, prompt, \u001B[38;5;28mrange\u001B[39m=\u001B[32m10\u001B[39m):\n\u001B[32m     27\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[33;03m    Filters and ranks models based on embedding similarity scores.\u001B[39;00m\n\u001B[32m     29\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     36\u001B[39m \u001B[33;03m        pd.DataFrame: Top N articles sorted by similarity score\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     39\u001B[39m     data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m].apply(\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m x: np.array(ast.literal_eval(x)) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x)  \u001B[38;5;66;03m#da sistemare\u001B[39;00m\n\u001B[32m     42\u001B[39m     data[\u001B[33m'\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m'\u001B[39m] = data[\u001B[33m'\u001B[39m\u001B[33membeddings\u001B[39m\u001B[33m'\u001B[39m].progress_apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: compute_score(x, prompt))\n\u001B[32m     43\u001B[39m     data.sort_values(by=\u001B[33m'\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m'\u001B[39m, ascending=\u001B[38;5;28;01mFalse\u001B[39;00m, inplace=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\ast.py:112\u001B[39m, in \u001B[36mliteral_eval\u001B[39m\u001B[34m(node_or_string)\u001B[39m\n\u001B[32m    110\u001B[39m                 \u001B[38;5;28;01mreturn\u001B[39;00m left - right\n\u001B[32m    111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _convert_signed_num(node)\n\u001B[32m--> \u001B[39m\u001B[32m112\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _convert(node_or_string)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\DigitalTwins\\Lib\\ast.py:86\u001B[39m, in \u001B[36mliteral_eval.<locals>._convert\u001B[39m\u001B[34m(node)\u001B[39m\n\u001B[32m     84\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m - operand\n\u001B[32m     85\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _convert_num(node)\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_convert\u001B[39m(node):\n\u001B[32m     87\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, Constant):\n\u001B[32m     88\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m node.value\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example with datasets from Hugging Face",
   "id": "7e4eac054ce92d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:51:37.683013Z",
     "start_time": "2025-06-12T10:51:32.065285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"Output/datasets_hg_embeddings.csv\")\n",
    "print(df.shape)"
   ],
   "id": "8a20e87cbe5f6bae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:27:55.918999Z",
     "start_time": "2025-06-12T10:27:55.908343Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "8f5fb3d51ff60bb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              dataset_id       author                 created_at  \\\n",
       "0          Nyameri/AIXDR      Nyameri  2023-11-03 05:19:15+00:00   \n",
       "1     agicorp/MetaMathQA      agicorp  2024-03-23 08:26:51+00:00   \n",
       "2  avsolatorio/medi-data  avsolatorio  2024-01-26 03:49:25+00:00   \n",
       "3         Yuanze/Olympus       Yuanze  2025-04-02 10:05:03+00:00   \n",
       "4       Laxhar/noob-wiki       Laxhar  2024-11-14 07:48:42+00:00   \n",
       "\n",
       "                                         readme_file  downloads  likes  \\\n",
       "0  # Dataset Card for Dataset Name\\n\\nThis datase...         28      1   \n",
       "1  View the project page:\\nhttps://meta-math.gith...         13      1   \n",
       "2  # MEDI dataset\\n\\nThis dataset was used in the...         15      0   \n",
       "3  # Olympus: A Universal Task Router for Compute...        179      5   \n",
       "4  # Noob SDXL Wiki\\n\\nThis is the WIKI database ...       2596     85   \n",
       "\n",
       "                                                tags language     license  \\\n",
       "0  ['task_categories:summarization', 'task_catego...      NaN         mit   \n",
       "1  ['license:mit', 'size_categories:100K<n<1M', '...      NaN         mit   \n",
       "2  ['size_categories:1M<n<10M', 'format:parquet',...      NaN         NaN   \n",
       "3  ['task_categories:question-answering', 'task_c...   ['en']  apache-2.0   \n",
       "4  ['task_categories:text-to-image', 'language:en...   ['en']  apache-2.0   \n",
       "\n",
       "  multilinguality size_categories  \\\n",
       "0             NaN    ['1K<n<10K']   \n",
       "1             NaN             NaN   \n",
       "2             NaN             NaN   \n",
       "3             NaN   ['100K<n<1M']   \n",
       "4             NaN             NaN   \n",
       "\n",
       "                                     task-categories  \\\n",
       "0            ['summarization', 'feature-extraction']   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  ['question-answering', 'visual-question-answer...   \n",
       "4                                  ['text-to-image']   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [ 0.09661677 -0.13288344  0.0624015  ... -0.01...  \n",
       "1  [ 0.24795215 -0.03745317  0.13433613 ... -0.02...  \n",
       "2  [ 0.11949765 -0.10292578  0.08450241 ... -0.02...  \n",
       "3  [ 0.04112962 -0.05431836  0.14046644 ... -0.02...  \n",
       "4  [ 0.06410673  0.02687506  0.06094188 ... -0.00...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>readme_file</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "      <th>language</th>\n",
       "      <th>license</th>\n",
       "      <th>multilinguality</th>\n",
       "      <th>size_categories</th>\n",
       "      <th>task-categories</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nyameri/AIXDR</td>\n",
       "      <td>Nyameri</td>\n",
       "      <td>2023-11-03 05:19:15+00:00</td>\n",
       "      <td># Dataset Card for Dataset Name\\n\\nThis datase...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>['task_categories:summarization', 'task_catego...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['1K&lt;n&lt;10K']</td>\n",
       "      <td>['summarization', 'feature-extraction']</td>\n",
       "      <td>[ 0.09661677 -0.13288344  0.0624015  ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agicorp/MetaMathQA</td>\n",
       "      <td>agicorp</td>\n",
       "      <td>2024-03-23 08:26:51+00:00</td>\n",
       "      <td>View the project page:\\nhttps://meta-math.gith...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>['license:mit', 'size_categories:100K&lt;n&lt;1M', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 0.24795215 -0.03745317  0.13433613 ... -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avsolatorio/medi-data</td>\n",
       "      <td>avsolatorio</td>\n",
       "      <td>2024-01-26 03:49:25+00:00</td>\n",
       "      <td># MEDI dataset\\n\\nThis dataset was used in the...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>['size_categories:1M&lt;n&lt;10M', 'format:parquet',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 0.11949765 -0.10292578  0.08450241 ... -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuanze/Olympus</td>\n",
       "      <td>Yuanze</td>\n",
       "      <td>2025-04-02 10:05:03+00:00</td>\n",
       "      <td># Olympus: A Universal Task Router for Compute...</td>\n",
       "      <td>179</td>\n",
       "      <td>5</td>\n",
       "      <td>['task_categories:question-answering', 'task_c...</td>\n",
       "      <td>['en']</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['100K&lt;n&lt;1M']</td>\n",
       "      <td>['question-answering', 'visual-question-answer...</td>\n",
       "      <td>[ 0.04112962 -0.05431836  0.14046644 ... -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laxhar/noob-wiki</td>\n",
       "      <td>Laxhar</td>\n",
       "      <td>2024-11-14 07:48:42+00:00</td>\n",
       "      <td># Noob SDXL Wiki\\n\\nThis is the WIKI database ...</td>\n",
       "      <td>2596</td>\n",
       "      <td>85</td>\n",
       "      <td>['task_categories:text-to-image', 'language:en...</td>\n",
       "      <td>['en']</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['text-to-image']</td>\n",
       "      <td>[ 0.06410673  0.02687506  0.06094188 ... -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:54:32.539845Z",
     "start_time": "2025-06-12T10:51:39.123686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset prompts\n",
    "user_prompts = [\n",
    "    \"Which datasets are best for sentiment analysis in Italian?\",\n",
    "    \"Find large-scale datasets with multilingual support and open licenses.\",\n",
    "    \"What are the top trending datasets for text summarization?\",\n",
    "    \"Datasets with detailed README files and active contributors.\",\n",
    "    \"Show datasets suitable for low-resource language modeling.\",\n",
    "    \"Which datasets support image classification tasks and are under 1GB?\",\n",
    "    \"List recently created datasets for question answering in biomedical domain.\",\n",
    "    \"Find datasets curated for cross-lingual classification tasks with labeled examples and language identifiers.\",\n",
    "    \"Find high-quality datasets for code generation with permissive licenses.\",\n",
    "    \"List benchmark NLP datasets commonly used in academic research and model evaluation.\"\n",
    "]\n",
    "\n",
    "# Log results\n",
    "with open(\"Results/datasets_results.txt\", \"w\", encoding=\"utf-8\") as log_file:\n",
    "    for i, prompt in enumerate(user_prompts, 1):\n",
    "        log_file.write(f\"\\n--- Query {i}: {prompt} ---\\n\")\n",
    "        filtered_df = filter_by_user_prompt(df, prompt)\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            log_file.write(f\"\\n{row['dataset_id']} | score: {row['score']:.4f}\\n\")\n",
    "            log_file.write(f\"Author: {row['author']}\\n\")\n",
    "            log_file.write(f\"Task Categories: {row['task-categories']}\\n\")\n",
    "            log_file.write(f\"ReadmeFile, first 500 characters: {row['readme_file'][:500]}\\n\")\n",
    "            log_file.write(\"-\" * 50 + \"\\n\")\n",
    "        log_file.write(\"\\n\")"
   ],
   "id": "98161d57651029f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 185031.12it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 211829.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 203206.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 222808.94it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 222813.67it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 219562.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 217973.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 216383.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 208886.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:00<00:00, 219499.77it/s]\n"
     ]
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
