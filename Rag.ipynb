{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T12:44:42.952077Z",
     "start_time": "2025-06-03T12:44:42.946947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "1d41ad80044b9777",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RAG: Query based retrival using embeddings\n",
    "### Overview\n",
    "The goal of this step is to filter and rank articles based on their embedding similarity scores to a user-provided prompt. This is done using a pre-trained model to convert the prompt into embeddings, and then comparing these embeddings with the embeddings of articles stored in a DataFrame. <br>\n",
    "\n",
    "The open source model is the same used before in the preprocessing step, which is [`jinaai/jina-embeddings-v3`](https://huggingface.co/jinaai/jina-embeddings-v3).\n",
    "\n",
    "#### Possibile future improvements\n",
    "The current filtering approach based on user queries can be expanded by incorporating additional criteria such as number of downloads, likes, or publication date. This a simple implementation which does not require any computational resources.<br>\n",
    "Moreover, the retrieval performance can be improved by experimenting with alternative similarity metrics such as cosine similarity or Euclidean distance or trying with another model.\n"
   ],
   "id": "73a3cee99e081526"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T12:44:42.981361Z",
     "start_time": "2025-06-03T12:44:42.974868Z"
    }
   },
   "source": [
    "embedding_model = \"jinaai/jina-embeddings-v3\"\n",
    "\n",
    "def convert_prompt_to_embedding(prompt):\n",
    "    \"\"\"\n",
    "    Converts text prompt to embeddings using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Input text to convert to embeddings\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Embedding vector representation of the input text\n",
    "    \"\"\"\n",
    "    model = AutoModel.from_pretrained(embedding_model, trust_remote_code=True).to(\"cpu\") # for now cpu\n",
    "    embedding = model.encode(prompt, task=\"text-matching\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return embedding\n",
    "\n",
    "def compute_score(embeddings, prompt):\n",
    "    models_embedding = np.array(embeddings)\n",
    "    return np.dot(models_embedding, prompt)\n",
    "\n",
    "def filter_by_score(data, prompt, range=10):\n",
    "    \"\"\"\n",
    "    Filters and ranks articles based on embedding similarity scores.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing 'embeddings' column\n",
    "        prompt (numpy.ndarray): Prompt embedding to compare against\n",
    "        range (int, optional): Number of top articles to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Top N articles sorted by similarity score\n",
    "    \"\"\"\n",
    "\n",
    "    data['embeddings'] = data['embeddings'].apply(lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else x) #da sistemare\n",
    "\n",
    "    data['score'] = data['embeddings'].progress_apply(lambda x: compute_score(x, prompt))\n",
    "    data.sort_values(by='score', ascending=False, inplace=True)\n",
    "    return data.head(range)\n",
    "\n",
    "\n",
    "def filter_by_user_prompt(data, user_prompt):\n",
    "    prompt_embedding = convert_prompt_to_embedding(user_prompt)\n",
    "    data = filter_by_score(data, prompt_embedding)\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T12:44:43.275864Z",
     "start_time": "2025-06-03T12:44:42.986911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"huggingface_models_embeddings.csv\")\n",
    "df.head()"
   ],
   "id": "fa78114ba453ebf0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                model_id                    base_model  \\\n",
       "0            ByteDance-Seed/BAGEL-7B-MoT  ['Qwen/Qwen2.5-7B-Instruct']   \n",
       "1           deepseek-ai/DeepSeek-R1-0528                           NaN   \n",
       "2  deepseek-ai/DeepSeek-R1-0528-Qwen3-8B                           NaN   \n",
       "3                  ResembleAI/chatterbox                           NaN   \n",
       "4  google/gemma-3n-E4B-it-litert-preview                           NaN   \n",
       "\n",
       "           author                                        readme_file  \\\n",
       "0  ByteDance-Seed  ü•Ø BAGEL ‚Ä¢ Unified Model for Multimodal Underst...   \n",
       "1     deepseek-ai  DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...   \n",
       "2     deepseek-ai  DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...   \n",
       "3      ResembleAI  Chatterbox TTS\\nMade with  ‚ù§Ô∏è  by\\nWe're excit...   \n",
       "4          google  [!Note]\\nThis repository corresponds to the Pr...   \n",
       "\n",
       "      license language  downloads  likes  \\\n",
       "0  apache-2.0      NaN       8217    931   \n",
       "1         mit      NaN      41622   1660   \n",
       "2         mit      NaN      55792    603   \n",
       "3         mit   ['en']          0    522   \n",
       "4       gemma      NaN          0    827   \n",
       "\n",
       "                                                tags        pipeline_tag  \\\n",
       "0  bagel-mot, any-to-any, arxiv:2505.14683, base_...          any-to-any   \n",
       "1  transformers, safetensors, deepseek_v3, text-g...     text-generation   \n",
       "2  transformers, safetensors, qwen3, text-generat...     text-generation   \n",
       "3  chatterbox, text-to-speech, speech generation,...      text-to-speech   \n",
       "4  image-text-to-text, arxiv:1905.07830, arxiv:19...  image-text-to-text   \n",
       "\n",
       "   library_name                 created_at  \\\n",
       "0     bagel-mot  2025-05-19 23:27:50+00:00   \n",
       "1  transformers  2025-05-28 09:46:42+00:00   \n",
       "2  transformers  2025-05-29 11:07:47+00:00   \n",
       "3    chatterbox  2025-04-24 12:03:33+00:00   \n",
       "4           NaN  2025-05-18 19:24:14+00:00   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.10378886014223099, -0.051912061870098114, 0...  \n",
       "1  [0.1293579787015915, -0.03305066004395485, 0.0...  \n",
       "2  [0.11969968676567078, -0.029439039528369904, 0...  \n",
       "3  [0.24664218723773956, 0.07128866761922836, 0.0...  \n",
       "4  [0.12829765677452087, -0.1102091372013092, 0.0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>base_model</th>\n",
       "      <th>author</th>\n",
       "      <th>readme_file</th>\n",
       "      <th>license</th>\n",
       "      <th>language</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>library_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteDance-Seed/BAGEL-7B-MoT</td>\n",
       "      <td>['Qwen/Qwen2.5-7B-Instruct']</td>\n",
       "      <td>ByteDance-Seed</td>\n",
       "      <td>ü•Ø BAGEL ‚Ä¢ Unified Model for Multimodal Underst...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8217</td>\n",
       "      <td>931</td>\n",
       "      <td>bagel-mot, any-to-any, arxiv:2505.14683, base_...</td>\n",
       "      <td>any-to-any</td>\n",
       "      <td>bagel-mot</td>\n",
       "      <td>2025-05-19 23:27:50+00:00</td>\n",
       "      <td>[0.10378886014223099, -0.051912061870098114, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-0528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td>DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41622</td>\n",
       "      <td>1660</td>\n",
       "      <td>transformers, safetensors, deepseek_v3, text-g...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-05-28 09:46:42+00:00</td>\n",
       "      <td>[0.1293579787015915, -0.03305066004395485, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-0528-Qwen3-8B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deepseek-ai</td>\n",
       "      <td>DeepSeek-R1-0528\\nPaper LinküëÅÔ∏è\\nIntroduction\\n...</td>\n",
       "      <td>mit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55792</td>\n",
       "      <td>603</td>\n",
       "      <td>transformers, safetensors, qwen3, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2025-05-29 11:07:47+00:00</td>\n",
       "      <td>[0.11969968676567078, -0.029439039528369904, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ResembleAI/chatterbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResembleAI</td>\n",
       "      <td>Chatterbox TTS\\nMade with  ‚ù§Ô∏è  by\\nWe're excit...</td>\n",
       "      <td>mit</td>\n",
       "      <td>['en']</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>chatterbox, text-to-speech, speech generation,...</td>\n",
       "      <td>text-to-speech</td>\n",
       "      <td>chatterbox</td>\n",
       "      <td>2025-04-24 12:03:33+00:00</td>\n",
       "      <td>[0.24664218723773956, 0.07128866761922836, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemma-3n-E4B-it-litert-preview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "      <td>[!Note]\\nThis repository corresponds to the Pr...</td>\n",
       "      <td>gemma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>image-text-to-text, arxiv:1905.07830, arxiv:19...</td>\n",
       "      <td>image-text-to-text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-18 19:24:14+00:00</td>\n",
       "      <td>[0.12829765677452087, -0.1102091372013092, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T12:45:39.474361Z",
     "start_time": "2025-06-03T12:44:43.316894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompts = [\n",
    "    \"What is the best model for text generation?\",\n",
    "    \"Which model should I use for sentiment analysis?\",\n",
    "    \"Find top models for image classification.\",\n",
    "    \"Best models for summarization tasks?\",\n",
    "    \"What are the newest models for code generation?\",\n",
    "    \"Top-performing models for question answering?\",\n",
    "    \"Which models support Italian language?\",\n",
    "    \"Best lightweight models for mobile deployment.\",\n",
    "    \"Which models are most popular on Hugging Face?\",\n",
    "    \"Find models optimized for speed and low latency.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Log results\n",
    "with open(\"rag_query_results_log.txt\", \"w\", encoding=\"utf-8\") as log_file:\n",
    "    for i, prompt in enumerate(user_prompts, 1):\n",
    "        log_file.write(f\"\\n--- Query {i}: {prompt} ---\\n\")\n",
    "        filtered_df = filter_by_user_prompt(df, prompt)\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            log_file.write(f\"\\n{row['model_id']} | score: {row['score']:.4f}\\n\")\n",
    "            log_file.write(f\"Author: {row['author']}\\n\")\n",
    "            log_file.write(f\"Pipeline Tag: {row['pipeline_tag']}\\n\")\n",
    "            # divider\n",
    "            log_file.write(\"-\" * 50 + \"\\n\")\n",
    "        log_file.write(\"\\n\")"
   ],
   "id": "bb2f36e33feadf8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 528730.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 42905.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 48051.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 108966.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 175971.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 134799.63it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 216895.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 108292.86it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1086/1086 [00:00<00:00, 166435.77it/s]\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
